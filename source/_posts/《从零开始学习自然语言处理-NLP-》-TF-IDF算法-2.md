---
title: 《从零开始学习自然语言处理(NLP)》-TF-IDF算法(2)
date: 2019-01-27 21:16:59
tags: 从零开始学习自然语言处理(NLP)
---
由于图片外链被禁止了，图片不能显示，完整文章看这里吧：<https://zhuanlan.zhihu.com/p/55843621>

# 写在最前面
在这个日新月异的信息时代，海量数据的积累，计算能力的不断提升，机器学习尤其是深度学习的蓬勃发展，使得人工智能技术在不同领域焕发出蓬勃的活力。自己经历了嵌入式开发，移动互联网开发，目前从事自然语言处理算法开发工作。从工程软件开发到自然语言处理算法开发，希望通过这个系列的文章，能够由浅入深，通俗易懂的介绍自然语言处理的领域知识，分享自己的成长，同大家一起进步。
# 问题描述
在上一篇文章中（[《《从零开始学习自然语言处理(NLP)》-倒排索引(1)》](https://zhuanlan.zhihu.com/p/55296265)）描述了基于关键词搜索的基本原理，以及通过倒排索引来提升和关键词相关网页的查询。本文在上文的基础上提出一个新的问题：
如果通过倒排索引查找到的网页都包含**全部的**查询关键字，而且，召回（符合查找条件）的网页数目又很多，这就需要将网页与查询Query的相关度进行排序了。相关度高的网页排在查询结果的前面，相关度低的网页排在后面。那问题来了，如何依据网页与查询关键词的相关性对召回的网页做排序呢？
# 基于TF（Term Frequency，词频）进行排序
最容易想到的便是基于词频打分进行排序，具体来说，对于查询Query：“林俊杰/2019/演唱会/行程”，下面的哪个网页跟查询Query的相关度更高呢？
**网页a**

    [林俊杰]/[2019]/全球/[演唱会]/[行程]/发布/，/这是/[林俊杰]/的/第/20/场/全球/巡演/。
	
|关键字|出现频次|
|------|------|
|林俊杰|2|
|2019|1|
|演唱会|1|
|行程|1|

**网页b**

    在 [林俊杰]/[2019]/全球/[演唱会]/[行程]/发布/之后/，/田馥甄/也/发布/了/今年/的/巡演/计划/，/她的/第一站/是/台北/。
	
|关键字|出现频次|
|------|------|
|林俊杰|1|
|2019|1|
|演唱会|1|
|行程|1|

显然网页a和Query的相关度更高。当然对于计算机就没有这么“显然”了，它需要依靠规则和具体算法来计算判断。基于词频的排序用公式表示就是，
    ![相关性计算](https://upload-images.jianshu.io/upload_images/4905018-2166358dc8c2fbae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
其中，
k：Query中查询关键词序号
![参数说明](https://upload-images.jianshu.io/upload_images/4905018-8c341c80a496862e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



为了方便计算，我们假设每个网页包含的词的总数为100，通过上面的公式，
**网页a**

    网页a相关度=2/100+1/100+1/100+1/100=0.05
**网页b**

    网页b相关度=1/100+1/100+1/100+1/100=0.04
通过上面的公式，计算机也能“显然”的判断，网页a与查询Query的相关度更高了。
# 基于TF排序的问题
假设现在有新的召回网页，
**网页c**

    在 [林俊杰]/[2019]/全球/[演唱会]/[行程]/发布/之后/，/众多/明星/也/都/发布/了/自己/[2019]年/的/巡演/计划/，/[行程]/安排/如下/，

|关键字|出现频次|
|------|------|
|林俊杰|1|
|2019|2|
|演唱会|1|
|行程|2|


    网页c相关度=1/100+2/100+1/100+2/100=0.06
显然基于词频的相关性计算公式，网页c（相关度0.06）大于网页a（相关度0.05），但真实情况是，网页c和查询Query的相关度，并没有网页a大。

# IDF（Inverse DocumentFrequency，逆文件词频）
上面的问题关键在于用户的查询Query主要关注的是"**林俊杰**"，至于"**2019**"，"**行程**"等信息也是在**林俊杰**的基础上展开的。所以，现在要解决的问题便是，排序算法如何能够凸显出"**林俊杰**"这个关键的查询信息。在这里便引入了IDF（Inverse DocumentFrequency，逆文件词频）。
我们先看下它的定义：
![IDF定义](https://upload-images.jianshu.io/upload_images/4905018-7e6f8bbd74473dc1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
其中，
分母的+1操作，是为了避免当所有文档都不包含该关键词时，分母出现为0的情况。
IDF的分子是固定的，所以，IDF的特性主要体现在分母上。
从IDF的定义可以看出，
**1 越是能代表特定内容的关键词，包含该关键词的网页越少，IDF值越高，如“林俊杰”**
**2 越是和内容主旨不相关的关键词，包含该关键词的网页越多，IDF值越低，如“2019”，“行程”**
所以，IDF值就能很好的体现出查询Query关键字，与需要查询内容的相关性。
# 基于TF-IDF进行排序
结合TF和IDF的特定，便有了TF-IDF，定义也非常直观，
![TF-IDF](https://upload-images.jianshu.io/upload_images/4905018-ad1332e689276ef9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
具体来说就是，一个网页与查询Query的相关性体现在：
**1 网页中包含查询关键词的频度**
**2 查询关键词对查询内容的反映程度**
基于TF-IDF，网页与查询Query的相关性，改写为，
![相关性定义](https://upload-images.jianshu.io/upload_images/4905018-de1a33712251872a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
其中，
![参数说明](https://upload-images.jianshu.io/upload_images/4905018-db90ca37a0c4ec6a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
在实际工程中，TF和IDF值，以及TF-IDF值针对于具体网页是提前计算好的，当搜索系统接收到用户的查询Query后，能够实时计算查询关键词与网页的相关度。
# 小结
本文沿用了[《《从零开始学习自然语言处理(NLP)》-倒排索引(1)》](https://zhuanlan.zhihu.com/p/55296265)中搜索的例子，提出了在网页包含所有查询关键词的情况下，如何对网页与查询Query的相关性进行排序。文中提出了基于TF的相关性排序方法，同时，也指出了该方法存在的问题。最终，引出TF-IDF算法：结合查询关键词在网页中的出现频率和该关键词反映查询内容程度两个特征，对召回网页进行排序。


















